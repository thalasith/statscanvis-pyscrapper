{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import sys\n",
    "sys.path.insert(1, os.getenv('LIBRARY_PATH'))\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import scrapper\n",
    "import data_pipeline\n",
    "from sqlalchemy import create_engine\n",
    "def upload_sql(query, data, table_name, latest_month, pick_member_1, pick_member_2, x, y):\n",
    "    conn_string = 'mysql+pymysql://' + os.environ[\"USERNAME\"] + ':' + os.environ[\"PASSWORD\"] + '@' + os.environ[\"HOST\"] + '/' + os.environ[\"DATABASE\"] \n",
    "    engine = create_engine(conn_string, connect_args={\n",
    "        \"ssl\": {\n",
    "            \"ssl_ca\": \"ca.pem\",\n",
    "            \"ssl_cert\": \"client-cert.pem\",\n",
    "            \"ssl_key\": \"client-key.pem\"\n",
    "        }\n",
    "    })\n",
    "    with engine.begin() as engine:\n",
    "        sql_data = pd.read_sql_query(query, engine)\n",
    "        sql_latest_month = sql_data[\"month\"].values[0]\n",
    "        \n",
    "        if (sql_latest_month == latest_month):\n",
    "            print(latest_month + \" \" + pick_member_1 + \" \"+ pick_member_2 + \" data already exists in \" + table_name + \" table\")\n",
    "        else:\n",
    "            data.to_sql(table_name, engine, if_exists=\"append\", index=False)\n",
    "            print(\"Inserted data from \" + x + \" and \" + y + \" into \" + table_name + \" successfully\")\n",
    "def clean_string(string):\n",
    "    return string.replace(\" \", \"_\").replace(\",\",\"\").replace(\"(\",\"\").replace(\")\",\"\").replace(\"-\",\"_\").replace(\"__\",\"_\").lower()[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Building the inputs for the scrapper\n",
    "industries_dict = {'3.1': 'industrial_aggregate_including_unclassified_businesses', '3.2': 'industrial_aggregate_excluding_unclassified_businesses', '3.3': 'goods_producing_industries', '3.4': 'forestry_logging_and_support', '3.10': 'mining_quarrying_and_oil_and_gas_extraction', '3.17': 'utilities', '3.21': 'construction', '3.34': 'manufacturing', '3.143': 'service_producing_industries', '3.144': 'trade', '3.215': 'transportation_and_warehousing', '3.253': 'information_and_cultural_industries', '3.267': 'finance_and_insurance', '3.284': 'real_estate_and_rental_and_leasing', '3.295': 'professional_scientific_and_technical_services', '3.306': 'management_of_companies_and_enterprises', '3.321': 'educational_services', '3.331': 'health_care_and_social_assistance', '3.354': 'arts_entertainment_and_recreation', '3.367': 'accommodation_and_food_services', '3.377': 'other_services_except_public_administration', '3.393': 'public_administration'}\n",
    "pick_members_2 = {\"names\": ['2.2'], \"values\": ['average_weekly_earnings']}\n",
    "pick_members_3 = {\"names\": ['3.1', '3.2', '3.3', '3.4', '3.10', '3.17', '3.21', '3.34', '3.143', '3.144', '3.215', '3.253', '3.267', '3.284', '3.295', '3.306', '3.321', '3.331', '3.354', '3.367', '3.377', '3.393'],\"values\": ['industrial_aggregate_including_unclassified_businesses', 'industrial_aggregate_excluding_unclassified_businesses', 'goods_producing_industries', 'forestry_logging_and_support', 'mining_quarrying_and_oil_and_gas_extraction', 'utilities', 'construction', 'manufacturing', 'service_producing_industries', 'trade', 'transportation_and_warehousing', 'information_and_cultural_industries', 'finance_and_insurance', 'real_estate_and_rental_and_leasing', 'professional_scientific_and_technical_services', 'management_of_companies_and_enterprises', 'educational_services', 'health_care_and_social_assistance', 'arts_entertainment_and_recreation', 'accommodation_and_food_services', 'other_services_except_public_administration', 'public_administration'] }\n",
    "pick_members_dict = {\"&pickMembers%5B0%5D=\": pick_members_2, \"&pickMembers%5B1%5D=\": pick_members_3}\n",
    "filter_names = {\"pick_member_1\": \"Estimate\", \"pick_member_2\": \"North American Industry Classification System (NAICS)\"}\n",
    "table_name = \"average_weekly_earnings_by_industry\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid=\"1410022301\"\n",
    "table_name = \"average_weekly_earnings_by_industry\"\n",
    "pick_members_dict = {\"&pickMembers%5B0%5D=\": pick_members_2, \"&pickMembers%5B1%5D=\": pick_members_3}\n",
    "filter_names = {\"pick_member_1\": \"Estimate\", \"pick_member_2\": \"North American Industry Classification System (NAICS)\"}\n",
    "transpose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "October 2022 average_weekly_earnings public_administration data already exists in average_weekly_earnings_by_industry table\n",
      "\u001b[32;1mData pipeline job completed for average_weekly_earnings_by_industry table at 2023-01-12\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "data_pipeline = data_pipeline.data_pipeline_job(pid=pid, table_name=table_name, pick_members_dict=pick_members_dict, filter_names=filter_names, transpose=transpose)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d057af1a5c49b4bed786b95378487de8898a19ac88ffccdd8bd5a4534c5371a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
