{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Initialization for Monthly Weekly Earnings by Industry</h1>\n",
    "\n",
    "This file is used to initialize the data table named \"monthly_weekly_earnings_by_industry\" in sql."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import sys\n",
    "sys.path.insert(1, os.getenv('LIBRARY_PATH'))\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import scrapper\n",
    "import data_pipeline\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_pick_members1 represents the provinces and list_pick_members2 represents the employee types (e.g. hourly vs salaried).\n",
    "list_pick_members1 = [\"1.1\", \"1.2\", \"1.3\", \"1.4\", \"1.5\", \"1.6\", \"1.7\", \"1.8\", \"1.9\", \"1.10\", \"1.11\", \"1.12\", \"1.14\", \"1.15\"]\n",
    "list_pick_members2 = [\"2.2\", \"2.3\"]\n",
    "# pid is the id of the table that we want to scrape.\n",
    "pid=str(1410020301)\n",
    "# startMonth and startYear represent the start date of the data we want to scrape.\n",
    "startMonth=\"01\"\n",
    "startYear=\"2022\"\n",
    "# endMonth and endYear represent the end date of the data we want to scrape.\n",
    "endMonth=\"12\"\n",
    "endYear=\"2022\"\n",
    "\n",
    "filter_names = [\"Geography\", \"Type of employees\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the two lists to create a list of tuples so we have all the combinations of the two lists.\n",
    "combined_list_picker = [(x, y) for x in list_pick_members1 for y in list_pick_members2]\n",
    "# creating the reference periods for the data we want to scrape. (note that this will be used in our URL)\n",
    "referencePeriods = startYear + startMonth + \"01\" + \"%2C\" + endYear + endMonth + \"28\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boristsao/Documents/Projects/stats-can-vis/statscanvis-pyscrapper/library/scrapper.py:33: FutureWarning: Possible nested set at position 2\n",
      "  new_string = re.sub(\"([[]).*?([]])\", '', string).replace(\" \", \"_\").replace(\",\",\"\").replace(\"(\",\"\").replace(\")\",\"\").replace(\"-\",\"_\").replace(\"__\",\"_\").lower()[:60]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted data from 1.1 and 2.2 into monthly_weekly_earnings_by_industry successfully\n",
      "Inserted data from 1.1 and 2.3 into monthly_weekly_earnings_by_industry successfully\n",
      "Inserted data from 1.2 and 2.2 into monthly_weekly_earnings_by_industry successfully\n",
      "Inserted data from 1.2 and 2.3 into monthly_weekly_earnings_by_industry successfully\n",
      "Inserted data from 1.3 and 2.2 into monthly_weekly_earnings_by_industry successfully\n",
      "Inserted data from 1.3 and 2.3 into monthly_weekly_earnings_by_industry successfully\n",
      "Inserted data from 1.4 and 2.2 into monthly_weekly_earnings_by_industry successfully\n",
      "Inserted data from 1.4 and 2.3 into monthly_weekly_earnings_by_industry successfully\n",
      "Inserted data from 1.5 and 2.2 into monthly_weekly_earnings_by_industry successfully\n",
      "Inserted data from 1.5 and 2.3 into monthly_weekly_earnings_by_industry successfully\n",
      "Inserted data from 1.6 and 2.2 into monthly_weekly_earnings_by_industry successfully\n",
      "Inserted data from 1.6 and 2.3 into monthly_weekly_earnings_by_industry successfully\n",
      "Inserted data from 1.7 and 2.2 into monthly_weekly_earnings_by_industry successfully\n",
      "Inserted data from 1.7 and 2.3 into monthly_weekly_earnings_by_industry successfully\n",
      "Inserted data from 1.8 and 2.2 into monthly_weekly_earnings_by_industry successfully\n",
      "Inserted data from 1.8 and 2.3 into monthly_weekly_earnings_by_industry successfully\n",
      "Inserted data from 1.9 and 2.2 into monthly_weekly_earnings_by_industry successfully\n",
      "Inserted data from 1.9 and 2.3 into monthly_weekly_earnings_by_industry successfully\n",
      "Inserted data from 1.10 and 2.2 into monthly_weekly_earnings_by_industry successfully\n",
      "Inserted data from 1.10 and 2.3 into monthly_weekly_earnings_by_industry successfully\n",
      "Inserted data from 1.11 and 2.2 into monthly_weekly_earnings_by_industry successfully\n",
      "Inserted data from 1.11 and 2.3 into monthly_weekly_earnings_by_industry successfully\n",
      "Inserted data from 1.12 and 2.2 into monthly_weekly_earnings_by_industry successfully\n",
      "Inserted data from 1.12 and 2.3 into monthly_weekly_earnings_by_industry successfully\n",
      "Inserted data from 1.14 and 2.2 into monthly_weekly_earnings_by_industry successfully\n",
      "Inserted data from 1.14 and 2.3 into monthly_weekly_earnings_by_industry successfully\n",
      "Inserted data from 1.15 and 2.2 into monthly_weekly_earnings_by_industry successfully\n",
      "Inserted data from 1.15 and 2.3 into monthly_weekly_earnings_by_industry successfully\n"
     ]
    }
   ],
   "source": [
    "# table_name is the name of the table we want to insert the data into.\n",
    "table_name = \"monthly_weekly_earnings_by_industry\"\n",
    "# conn_string is the connection string to the database.\n",
    "ssl_args = {'ssl_ca': \"/etc/ssl/cert.pem\"}\n",
    "\n",
    "conn_string = 'mysql+pymysql://' + os.getenv(\"USERNAME\") + ':' + os.getenv(\"PASSWORD\") + '@' + os.getenv(\"HOST\") + '/' + os.getenv(\"DATABASE\") \n",
    "\n",
    "# iterate through the list of tuples and scrape the data from the URL and insert it into the database.\n",
    "for x, y in combined_list_picker:\n",
    "    url = 'https://www150.statcan.gc.ca/t1/tbl1/en/tv.action?pid=' + pid + '&pickMembers%5B0%5D='+ x + '&pickMembers%5B1%5D='+ y + '&cubeTimeFrame.startMonth='+ startMonth + '&cubeTimeFrame.startYear=' + startYear + '&cubeTimeFrame.endMonth=' + endMonth + '&cubeTimeFrame.endYear=' + endYear + '&referencePeriods=' + referencePeriods\n",
    "    df = scrapper.simple_scrapper(url, filter_names)\n",
    "    df.rename(columns = {'type_of_employees':'type_of_employee'}, inplace = True)\n",
    "    engine = create_engine(conn_string, connect_args=ssl_args)\n",
    "    with engine.begin() as engine:\n",
    "        df.to_sql(table_name, engine, if_exists='append', index=False)\n",
    "        print(\"Inserted data from \" + x + \" and \" + y + \" into \" + table_name + \" successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 11 2022, 13:40:36) \n[Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "761f37a02670cca8f02730e2c7755870b61864280cbbc348b34c69106b58d481"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
